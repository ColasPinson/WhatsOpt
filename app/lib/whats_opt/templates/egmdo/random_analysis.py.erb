import os
import numpy as np
from numpy import nan, inf
import pickle
import openturns as ot

import openmdao.api as om
<% if @impl.nonlinear_solver.reckless? -%>
from openmdao_extensions.reckless_nonlinear_block_gs import RecklessNonlinearBlockGS
<% else -%>
from openmdao.api import <%= @impl.nonlinear_solver.name %>
<% end -%>
from openmdao.api import NewtonSolver
from openmdao.api import <%= @impl.linear_solver.name %>
from openmdao_extensions.smt_doe_driver import SmtDOEDriver
from openmdao_extensions.openturns_doe_driver import OpenturnsDOEDriver
<%- @mda.plain_disciplines.each do |disc| -%>
<%- if disc.openmdao_impl&.egmdo_surrogate -%>

class <%= disc.py_classname %>RandomDiscipline(om.ExplicitComponent):
    """ An OpenMDAO base component to encapsulate <%= disc.py_classname %> discipline """
    def __init__(self, gp_factory, **kwargs):
        super().__init__(**kwargs)
<%- disc.output_variables.each do |v| -%>        
        with open(gp_factory.gp_filename("<%= disc.snake_modulename %>", "<%= v.py_varname %>"), 'rb') as f:
            self.gp_<%= v.py_varname %> = pickle.load(f) 
<%- end %>

<%- unless disc.variables.empty? -%>
    def setup(self):
<%- disc.input_variables.numeric.each do |var| %>
        self.add_input('<%= var.py_varname %>', val=<%= var.init_py_value %>, desc='<%= var.escaped_desc %>'<%= @impl.use_units && !var.units.blank? ? ", units='#{var.units}'":"" %>)<%- end %>
<%- disc.output_variables.each do |var| %>
        self.add_input('_xi_<%= var.py_varname %>', val=0.0)<%- end %>
<%- disc.output_variables.numeric.each do |var| -%>
<%- if var.scaling.blank? -%>
        self.add_output('<%= var.py_varname %>', val=<%= var.init_py_value %>, desc='<%= var.escaped_desc %>'<%= @impl.use_units && !var.units.blank? ? ", units='#{var.units}'":"" %>)
<%- else -%>
        self.add_output('<%= var.py_varname %>', val=<%= var.init_py_value %>, desc='<%= var.escaped_desc %>',
                        ref=<%= var.scaling_ref_py_value %>, ref0=<%= var.scaling_ref0_py_value %>, res_ref=<%= var.scaling_res_ref_py_value %><%= @impl.use_units && !var.units.blank? ? ", units='#{var.units}'":"" %>)
<%- end -%>
<%- end -%>
        self.declare_partials('*', '*')

    def compute(self, inputs, outputs):
        inputs_gp = np.array([])
        random_inputs = []
<% disc.output_variables.each_with_index do |v| %>
        random_inputs.append('_xi_<%= v.py_varname %>')
<% end %>
        for name in sorted(inputs.keys()):
            if name not in random_inputs: 
                inputs_gp = np.concatenate((inputs_gp, inputs[name]))
        inputs_gp = np.atleast_2d(inputs_gp)    
<% disc.output_variables.each_with_index do |v|%>        
        sigma = np.sqrt(self.gp_<%= v.py_varname %>.predict_variances(inputs_gp))
        mean = self.gp_<%= v.py_varname %>.predict_values(inputs_gp)
        outputs['<%= v.py_varname %>'] = mean + inputs['_xi_<%= v.py_varname %>'] * sigma 
<%- end -%>

    def compute_partials(self, inputs, partials):
        """ Jacobian for Discipline1 """
<%- disc.output_variables.numeric.each do |var_out| -%>
<%- disc.input_variables.numeric.each do |var_in| -%>
        partials['<%= var_out.py_varname %>', '<%= var_in.py_varname %>'] = np.zeros((<%= var_out.dim %>, <%= var_in.dim %>))
<%- end -%>
<%- disc.output_variables.numeric.each do |var_in| -%>
        partials['<%= var_out.py_varname %>', '_xi_<%= var_in.py_varname %>'] = np.zeros((<%= var_out.dim %>, <%= var_in.dim %>))
<%- end -%>
<%- end -%>

        inputs_gp = np.array([])
        random_inputs = []

<%- disc.output_variables.each_with_index do |v| -%>
        random_inputs.append('_xi_<%= v.py_varname %>')
<%- end -%>

        for name in sorted(inputs.keys()):
            if name not in random_inputs: 
                inputs_gp = np.concatenate((inputs_gp, inputs[name]))
        inputs_gp = np.atleast_2d(inputs_gp)
        i = 0
<%- disc.output_variables.each_with_index do |v| -%>        
        sigma = np.sqrt(self.gp_<%= v.py_varname %>.predict_variances(inputs_gp))
        d_sigma = self.gp_<%= v.py_varname %>.predict_variance_derivatives(inputs_gp)/(2.0*sigma)
        for name in sorted(inputs.keys()):
            if name in random_inputs:
                sigma = np.sqrt(self.gp_<%= v.py_varname %>.predict_variances(inputs_gp))
                partials['<%= v.py_varname %>','_xi_<%= v.py_varname %>'] = sigma
            else:
                dim = partials['<%= v.py_varname %>', name].shape[1]
                for j in range(dim):
                    d_mean = self.gp_<%= v.py_varname %>.predict_derivatives(inputs_gp, i)
                    partials['<%= v.py_varname %>', name][0, j] = d_mean + inputs['_xi_<%= v.py_varname %>'] * d_sigma[0, i]
                    i = i + 1
<%- end -%>

<%- end -%>
<%- end -%>
<%- end -%>


class <%= @mda.py_classname %>RandomAnalysis(<%= @impl.parallel_group ? "om.ParallelGroup" : "om.Group" %>):
    """ An OpenMDAO base component to encapsulate <%= @mda.py_classname %> random MDA """
    def __init__(self, discipline_factory, gp_factory, **kwargs):
        super(). __init__(**kwargs)
        self.disc_factory = discipline_factory
        self.gp_factory = gp_factory

        self.nonlinear_solver = NewtonSolver(solve_subsystems=False)
<% unless @impl.nonlinear_solver.runonce? -%>
        self.nonlinear_solver.options['atol'] = <%= @impl.nonlinear_solver.atol %>
        self.nonlinear_solver.options['rtol'] = <%= @impl.nonlinear_solver.rtol %>
        self.nonlinear_solver.options['err_on_non_converge'] = <%= @impl.to_code(:nonlinear_solver, :err_on_non_converge) %>
        self.nonlinear_solver.options['iprint'] = <%= @impl.nonlinear_solver.iprint %>
        self.nonlinear_solver.options['maxiter'] = <%= @impl.nonlinear_solver.maxiter %>
<% end -%>

        self.linear_solver = <%= @impl.linear_solver.name %>()
        self.linear_solver.options['atol'] = <%= @impl.linear_solver.atol %>
        self.linear_solver.options['rtol'] = <%= @impl.linear_solver.rtol %>
        self.linear_solver.options['err_on_non_converge'] = <%= @impl.to_code(:linear_solver, :err_on_non_converge) %>
        self.linear_solver.options['iprint'] = <%= @impl.linear_solver.iprint %>
        self.linear_solver.options['maxiter'] = <%= @impl.linear_solver.maxiter %>

    def setup(self):
<%- @mda.input_variables.each do |dv| -%>
        self.set_input_defaults('<%= dv.name %>', val=<%= dv.init_py_value %><%= @impl.use_units && !dv.units.blank? ? ", units='#{dv.units}'":"" %>)
<%- end -%>
<%- @mda.egmdo_random_variables.each do |v| -%>
        self.set_input_defaults('_xi_<%= v.name %>', val=0.0)
<%- end -%>

<%- @mda.plain_disciplines.each do |disc| -%>
<%- if disc.openmdao_impl&.egmdo_surrogate -%>
        name = '<%= disc.py_classname %>Random'
        disc = <%= disc.py_classname %>RandomDiscipline(self.gp_factory)
<%- else -%>
        name = '<%= disc.py_classname %>'
        disc = self.disc_factory.create_<%= disc.snake_modulename %>()
<%- end -%>
        self.add_subsystem(name, disc, promotes=['*'])
<%- end -%>


def run_doe(discipline_factory, gp_factory, design_vars, n_cases, out_sqlitefilename, parallel=False):
    pb = om.Problem(<%= @mda.py_classname %>RandomAnalysis(discipline_factory, gp_factory))
    dists = []
    <% dim = 0 %>
    <%- @mda.egmdo_random_variables.each do |param| -%>
    # _xi_<%= param.py_varname %> 
    dists.append(ot.Normal(0.0, 1.0))
    <%- dim = dim + 1 -%>
    <%- end -%>

    # Dependency between variables can be specified by choosing a specific copula
    copula = ot.IndependentCopula(<%= dim %>)  # default to no dependency

    comp_dist = ot.ComposedDistribution(dists, copula)
    pb.driver = OpenturnsDOEDriver(n_samples=n_cases, distribution=comp_dist)
    pb.driver.options['run_parallel'] = parallel

    recorder = om.SqliteRecorder(out_sqlitefilename)
    pb.driver.add_recorder(recorder)
    pb.driver.recording_options['includes'] = ['*']

    if os.path.exists(out_sqlitefilename):
        os.remove(out_sqlitefilename)

    # uncertain variable input are taken as design_variables to get recorded by driver recorder
    <%- @mda.egmdo_random_variables.each do |dv| -%>
    pb.model.add_design_var('_xi_<%= dv.py_varname %>', lower=<%= dv.lower_py_value %>, upper=<%= dv.upper_py_value %>)
    <%- end -%>
    pb.setup()  
    for name, val in design_vars.items():
        pb[name] = val
    <%- @mda.egmdo_random_variables.each do |param| -%>
    pb['_xi_<%= param.py_varname %>'] = 0.0
    <%- end -%>
    pb.run_driver()
    pb.cleanup()


def run_random_mda(discipline_factory, gp_factory, design_vars, n_doe_pce, outdir='.', threshold_coeff_var=1e-3):
    # run the random MDA n times to create a doe
    outfile = os.path.join(outdir, '<%= @mda.snake_modulename %>_random_mda_doe.sqlite')
    run_doe(discipline_factory, gp_factory, design_vars, n_doe_pce, outfile)

    # Quantities of interest
    qoi_names = []
<%- @mda.constraint_variables.each do |c| -%>
    qoi_names.append("<%= c.name %>")
<%- end -%>
    qoi_names.append("<%= @mda.objective_variables.first.py_varname %>")

    # open the doe to create the PCE
    cr = om.CaseReader(outfile)
    driver_cases = cr.list_cases('driver', out_stream=None)
    case = cr.get_case(driver_cases[0])
    n_doe = len(driver_cases)
    n_des_var = len(case.get_design_vars()) 
    doe = np.zeros((n_doe, n_des_var + len(qoi_names)))
    des_var_names = sorted(case.get_design_vars())

    coupling_var_doe = np.zeros((n_doe, <%= @mda.coupling_variables.size %>))
    for i in range(n_doe):
        case = cr.get_case(driver_cases[i])
        for j in range(n_des_var):
            doe[i, j] = case.outputs[des_var_names[j]]   
        doe[i, -1] = case["<%= @mda.objective_variables.first.py_varname %>"]
<% nb_cstrs = @mda.constraint_variables.size %>
<%- @mda.constraint_variables.each_with_index do |cstr_var, k| -%>        
        doe[i, <%= -(nb_cstrs+1)+k %>] = case["<%= cstr_var.py_varname %>"]
<%- end -%>
<%- @mda.coupling_variables.each_with_index do |cv, j| -%>
        coupling_var_doe[i, <%= j %>] = case["<%= cv.py_varname %>"]
<%- end -%>
    print("Estimated mean of the output = ", doe[:, -1].mean())
    print("Estimated coeff of var of the output = ", doe[:, -1].std()/doe[:, -1].mean())

    # Polynomial chaos expansion metamodel
    # Determination of the most uncertain variable between the n constraints and the objective function
    # Warning : the constraints values tend towards 0 thus their coef of var tends towards +inf. 
    # We use a threshold to compute with standard deviation and not with coef of var  
    mean = doe[:, <%= -nb_cstrs-1 %>:].mean(axis=0)
    std =  doe[:, <%= -nb_cstrs-1 %>:].std(axis=0)
    # Threshold
    ind = abs(mean) < threshold_coeff_var
    cv = std/abs(mean)
    cv[ind] = std[ind]
    max_cv = cv.max()
    index = cv.argmax()
    
    print(f"The most uncertain QoI is '{qoi_names[index]}' with mean = {mean[index]} and estimated coeff of var = {max_cv}")

    # degree of the expansion 
    degree = 3
    distribution = ot.Normal(n_des_var)
    basis = [ot.StandardDistributionPolynomialFactory(distribution.getMarginal(i)) for i in range(n_des_var)]
    enumerateFunction = ot.LinearEnumerateFunction(n_des_var)
    productBasis = ot.OrthogonalProductPolynomialFactory(basis, enumerateFunction)
    adaptiveStrategy = ot.FixedStrategy(productBasis, enumerateFunction.getStrataCumulatedCardinal(degree))
    projectionStrategy = ot.LeastSquaresStrategy()
    algo = ot.FunctionalChaosAlgorithm(doe[:, 0:-len(qoi_names)], np.atleast_2d(doe[:, -(len(qoi_names)-index)]).T, 
                                       distribution, adaptiveStrategy, projectionStrategy)
    algo.run()
    result = algo.getResult()

    # sensitivity analysis
    sensitivityAnalysis = ot.FunctionalChaosSobolIndices(result)
    first_order = [sensitivityAnalysis.getSobolIndex(i) for i in range(n_des_var)]
    print("First order Sobol indices =", first_order)
    print("Sum of the first order Sobol indices =", np.array(first_order).sum())
    max_effect_varname = des_var_names[np.array(first_order).argmax()][4:]  # remove prefix _xi_
    print(f"Most relevant variable = '{max_effect_varname}'")
    return max_cv, max_effect_varname, coupling_var_doe
